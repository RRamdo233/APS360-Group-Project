{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_list = next(os.walk('../Data/Images'))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Data/Labels.csv\"\n",
    "header = ['Run','AD']\n",
    "Labelsdf = pd.read_csv(path, names=header, usecols=[1,2], skiprows=1, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(Labelsdf.Run, Labelsdf.AD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# BASELINE RGB\n",
    "img_dir = \"../Data/Images\"\n",
    "low_bound = 100\n",
    "high_bound = 200\n",
    "img_scale = 1\n",
    "depth_scale = 33\n",
    "#list of tuples (image data, AD)\n",
    "train_data, valid_data, test_data = [], [], []\n",
    "for run in runs_list:\n",
    "    print(run)\n",
    "    run_dir = os.path.join(img_dir, run)\n",
    "    run_imgs = []\n",
    "    for filename in os.listdir(run_dir):\n",
    "        img_num = int(filename[-7:-4])\n",
    "        if (100 <= img_num < 199):\n",
    "            img_slice = cv2.imread(os.path.join(run_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            #print(img_slice)\n",
    "            #img_slice = cv2.resize(img_slice, (0,0), fx=1/img_scale, fy=1/img_scale, interpolation=cv2.INTER_AREA)\n",
    "            #img_slice = img_slice[40:216,:]\n",
    "            img_slice = img_slice/256\n",
    "            run_imgs.append(img_slice)\n",
    "\n",
    "    temp_arr = np.array(run_imgs)\n",
    "    \n",
    "    if temp_arr.size == 0 or temp_arr.shape[1] != 256 or temp_arr.shape[2] != 176:\n",
    "#         print(run)\n",
    "#         print(temp_arr.shape)\n",
    "        continue\n",
    "    \n",
    "    # add black bars on the left/right\n",
    "#     i = 0\n",
    "    temp_imgs = []\n",
    "    for img_slice in temp_arr:\n",
    "#         print(i)\n",
    "#         i += 1\n",
    "        final_slice = np.zeros([256,256])\n",
    "        final_slice[:, 40:216] = img_slice\n",
    "#         plt.imshow(final_slice)\n",
    "#         plt.show()\n",
    "        temp_imgs.append(final_slice)\n",
    "    \n",
    "    temp_arr = np.array(temp_imgs)\n",
    "    \n",
    "    final_slices = []\n",
    "    #print(temp_arr.shape[2])\n",
    "    \n",
    "    for y in range(temp_arr.shape[2]):\n",
    "        xz_pane = temp_arr[:, :, y]\n",
    "        scaled_xz = cv2.resize(xz_pane, (0, 0), fy=1/depth_scale, fx=1, interpolation=cv2.INTER_AREA)\n",
    "        final_slices.append(scaled_xz)\n",
    "    \n",
    "    if not len(final_slices[0]) == 3:\n",
    "        continue\n",
    "    \n",
    "    final_array = torch.from_numpy(np.dstack(final_slices)).float()\n",
    "    #print(final_array.shape)\n",
    "    run_tuple = (final_array, labels_dict[run])\n",
    "    \n",
    "    subject_regex = re.compile(\"OAS(?P<order>[0-9]+)\")\n",
    "    subject = subject_regex.search(run).group(1)\n",
    "    \n",
    "    if int(subject[-2]) < 6:\n",
    "        train_data.append(run_tuple)\n",
    "    elif 6 <= int(subject[-2]) <=7:\n",
    "        valid_data.append(run_tuple)\n",
    "    elif 8 <= int(subject[-2]) <= 9:\n",
    "        test_data.append(run_tuple)\n",
    "    \n",
    "    \n",
    "print(\"Number of data points in train dataset: {}\".format(len(train_data)))\n",
    "print(\"Number of data points in valid dataset: {}\".format(len(valid_data)))\n",
    "print(\"Number of data points in test dataset: {}\".format(len(test_data)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(valid_data[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(x[1] for x in train_data)\n",
    "print(\"Number of non-AD scans in train dataset: {}\".format(counts[0]))\n",
    "print(\"Number of AD scan in train datasets: {}\".format(counts[1]))\n",
    "print(\"\\n\")\n",
    "\n",
    "counts = Counter(x[1] for x in valid_data)\n",
    "print(\"Number of non-AD scans in valid dataset: {}\".format(counts[0]))\n",
    "print(\"Number of AD scan in valid datasets: {}\".format(counts[1]))\n",
    "print(\"\\n\")\n",
    "\n",
    "counts = Counter(x[1] for x in test_data)\n",
    "print(\"Number of non-AD scans in test dataset: {}\".format(counts[0]))\n",
    "print(\"Number of AD scan in test datasets: {}\".format(counts[1]))\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train_data = train_data\n",
    "train_AD = []\n",
    "for item in train_data:\n",
    "    if item[1] == 1:\n",
    "        train_AD.append(item)\n",
    "train_data = old_train_data + train_AD * 4\n",
    "\n",
    "print(\"Number of data points in new train dataset: {}\".format(len(train_data)))\n",
    "counts = Counter(x[1] for x in train_data)\n",
    "print(\"Number of non-AD scans in new train dataset: {}\".format(counts[0]))\n",
    "print(\"Number of AD scan in new train dataset: {}\".format(counts[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class T1Dataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        # list of tuples (3d image arrays, AD label)\n",
    "        self.data = data\n",
    "        # labels.csv\n",
    "        #self.target = torch.from_numpy(target).long()\n",
    "        #self.transform = transforms.Compose([transforms.ToTensor()])\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #scan = torch.from_numpy(self.data[index][0]).float()\n",
    "        scan = self.data[index][0]\n",
    "        y = self.data[index][1]\n",
    "        return scan, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = T1Dataset(train_data, None)\n",
    "valid_dataset = T1Dataset(valid_data, None)\n",
    "test_dataset = T1Dataset(test_data, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models\n",
    "\n",
    "alexnet = torchvision.models.alexnet(pretrained=True)\n",
    "alexnet.cuda()\n",
    "\n",
    "train_dataset_list = list(train_dataset)\n",
    "imgs, train_labels = next(iter(torch.utils.data.DataLoader(train_dataset_list, batch_size=256, shuffle=True)))\n",
    "imgs = imgs.float()\n",
    "imgs = imgs.to(device)\n",
    "train_features = alexnet.features(imgs)\n",
    "\n",
    "valid_dataset_list = list(valid_dataset)\n",
    "imgs, valid_labels = next(iter(torch.utils.data.DataLoader(valid_dataset_list, batch_size=256, shuffle=True)))\n",
    "imgs = imgs.float()\n",
    "imgs = imgs.to(device)\n",
    "valid_features = alexnet.features(imgs)\n",
    "\n",
    "test_dataset_list = list(test_dataset)\n",
    "imgs, test_labels = next(iter(torch.utils.data.DataLoader(test_dataset_list, batch_size=256, shuffle=True)))\n",
    "imgs = imgs.float()\n",
    "imgs = imgs.to(device)\n",
    "test_features = alexnet.features(imgs)\n",
    "\n",
    "print(imgs.shape)\n",
    "print(len(test_dataset_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(imgs[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_list = []\n",
    "for i in range(train_features.shape[0]):\n",
    "    train_features_list.append((train_features[i], train_labels[i]))\n",
    "    \n",
    "valid_features_list = []\n",
    "for i in range(valid_features.shape[0]):\n",
    "    valid_features_list.append((valid_features[i], valid_labels[i]))\n",
    "    \n",
    "test_features_list = []\n",
    "for i in range(test_features.shape[0]):\n",
    "    test_features_list.append((test_features[i], test_labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_name(name, batch_size, learning_rate, epoch):\n",
    "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
    "                                                   batch_size,\n",
    "                                                   learning_rate,\n",
    "                                                   epoch)\n",
    "    return path\n",
    "\n",
    "def get_loss(model, train=False):\n",
    "    if train:\n",
    "        data = train_features_list\n",
    "    else:\n",
    "        data = test_features_list\n",
    "        \n",
    "    loader = torch.utils.data.DataLoader(data, batch_size=len(data), shuffle=True)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    imgs, labels = next(iter(loader))\n",
    "    imgs, labels = imgs.to(device), labels.to(device)\n",
    "    out = model(imgs)             # forward pass\n",
    "    loss = criterion(out, labels.float()) # compute the total loss\n",
    "    return loss.item()\n",
    "\n",
    "def get_accuracy(model, train=False):\n",
    "    if train:\n",
    "        data = train_features_list\n",
    "    else:\n",
    "        #data_acc_loader = torch.utils.data.DataLoader(data_val, batch_size=diff)\n",
    "        data = valid_features_list\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in torch.utils.data.DataLoader(data, batch_size=32, shuffle=True):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs) # We don't need to run F.softmax\n",
    "        corr = (outputs > 0.0).squeeze().long() == labels\n",
    "        correct += int(corr.sum())\n",
    "        #correct += pred.eq(labels.view_as(pred)).sum().item()\n",
    "        total += imgs.shape[0]\n",
    "    #print(total)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(model, features_list, num_epochs=10, batch_size=32, learning_rate=1e-4):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # use Adam for CNN\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "    epochs, train_losses, valid_losses, train_acc, valid_acc = [], [], [], [], []\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(features_list, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, labels in iter(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #print(torch.sum(inputs))\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.float())\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "            #for param in model.parameters():\n",
    "            #  print(param.grad.data.sum())\n",
    "    \n",
    "        epochs.append(epoch)\n",
    "        train_losses.append(get_loss(model, train=True))\n",
    "        valid_losses.append(get_loss(model, train=False))\n",
    "        train_acc.append(get_accuracy(model, train=True))\n",
    "        valid_acc.append(get_accuracy(model, train=False))\n",
    "        \n",
    "        print(\"Epoch %d; Train Loss %f; Val Loss %f; Train Acc %f; Val Acc %f\" % (\n",
    "              epoch+1, loss, valid_losses[-1], train_acc[-1], valid_acc[-1]))\n",
    "    \n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epochs, train_losses, label=\"Train\")\n",
    "    plt.plot(epochs, valid_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"Training Curve\")\n",
    "    plt.plot(epochs, train_acc, label=\"Train\")\n",
    "    plt.plot(epochs, valid_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
    "    print(\"Final Validation Accuracy: {}\".format(valid_acc[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.name = \"CNN2\"\n",
    "        # 256x6x6\n",
    "        self.fc1 = nn.Linear(256*7*7, 512)\n",
    "        nn.init.xavier_uniform(self.fc1.weight)\n",
    "        #self.fc1 = nn.Linear(3*224*224, 512)\n",
    "        self.fc2 = nn.Linear(512, 32)\n",
    "        nn.init.xavier_uniform(self.fc2.weight)\n",
    "        #self.fc3 = nn.Linear(512, 64)\n",
    "        #nn.init.xavier_uniform(self.fc3.weight)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        nn.init.xavier_uniform(self.fc3.weight)\n",
    "        #self.softmax = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 256*7*7)\n",
    "        #x = x.view(-1, 3*224*224)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #print(x.shape)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        #print(x.shape)\n",
    "        #x = self.fc4(x)\n",
    "        #x = self.softmax(x)\n",
    "        x = x.squeeze(1) # Flatten to [batch_size]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alexnetCNN2 = CNN2()\n",
    "alexnetCNN2.cuda()\n",
    "train(alexnetCNN2, train_features_list, num_epochs=50, batch_size=32, learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in alexnetCNN2.parameters():\n",
    "    print(param.grad.data.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_accuracy(alexnetCNN2, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
