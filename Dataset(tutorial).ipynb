{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.0.1\n",
      "Torchvision Version:  0.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "import copy\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "# CUDA for PyTorch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_list = next(os.walk('../Data/Images'))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../Data/Labels.csv\"\n",
    "header = ['Run','AD']\n",
    "Labelsdf = pd.read_csv(path, names=header, usecols=[1,2], skiprows=1, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = dict(zip(Labelsdf.Run, Labelsdf.AD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# BASELINE RGB\n",
    "img_dir = \"../Data/Images\"\n",
    "low_bound = 100\n",
    "high_bound = 200\n",
    "img_scale = 1\n",
    "depth_scale = 33\n",
    "\n",
    "imgs, labels = [], []\n",
    "\n",
    "for run in runs_list:\n",
    "    run_dir = os.path.join(img_dir, run)\n",
    "    run_imgs = []\n",
    "    print(run_dir)\n",
    "    for filename in os.listdir(run_dir):\n",
    "        img_num = int(filename[-7:-4])\n",
    "        if (100 <= img_num < 199):\n",
    "            img_slice = cv2.imread(os.path.join(run_dir, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img_slice = img_slice/256\n",
    "            run_imgs.append(img_slice)\n",
    "\n",
    "    temp_arr = np.array(run_imgs)\n",
    "    \n",
    "    if temp_arr.size == 0 or temp_arr.shape[1] != 256 or temp_arr.shape[2] != 176:\n",
    "        continue\n",
    "\n",
    "    # add black bars on the left/right\n",
    "    temp_imgs = []\n",
    "    for img_slice in temp_arr:\n",
    "        final_slice = np.zeros([256,256])\n",
    "        final_slice[:, 40:216] = img_slice\n",
    "        temp_imgs.append(final_slice)\n",
    "    \n",
    "    temp_arr = np.array(temp_imgs)\n",
    "    \n",
    "    final_slices = []\n",
    "    \n",
    "    for y in range(temp_arr.shape[2]):\n",
    "        xz_pane = temp_arr[:, :, y]\n",
    "        scaled_xz = cv2.resize(xz_pane, (0, 0), fy=1/depth_scale, fx=1, interpolation=cv2.INTER_AREA)\n",
    "        final_slices.append(scaled_xz)\n",
    "    \n",
    "    if not len(final_slices[0]) == 3:\n",
    "        continue\n",
    "    \n",
    "    final_array = np.dstack(final_slices)\n",
    "    # Doesn't exist in labels\n",
    "    if run in labels_dict:\n",
    "        imgs.append(final_array)\n",
    "        labels.append(labels_dict[run])\n",
    "\n",
    "imgs = np.array(imgs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n",
    "model_name = \"densenet\"\n",
    "\n",
    "# Number of classes in the dataset\n",
    "num_classes = 2\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "\n",
    "# Number of epochs to train for\n",
    "num_epochs = 15\n",
    "\n",
    "# Flag for feature extracting. When False, we finetune the whole model,\n",
    "#   when True we only update the reshaped layer params\n",
    "feature_extract = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_imgs, ad_labels = [], []\n",
    "\n",
    "for idx, ad in np.ndenumerate(labels):\n",
    "    if ad:\n",
    "        ad_imgs.append(imgs[idx])\n",
    "        ad_labels.append(1)\n",
    "\n",
    "ad_imgs = np.array(ad_imgs)\n",
    "ad_labels = np.array(ad_labels)\n",
    "\n",
    "normal_ratio = imgs.shape[0] // ad_imgs.shape[0]\n",
    "\n",
    "new_imgs = np.concatenate((imgs, np.repeat(ad_imgs, normal_ratio, axis=0)), axis=0)\n",
    "new_labels = np.concatenate((labels, np.repeat(ad_labels, normal_ratio, axis=0)), axis=0)\n",
    "\n",
    "# new_imgs = imgs\n",
    "# new_labels = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T1Dataset(Dataset):\n",
    "    def __init__(self, data, target, transform=None):\n",
    "        self.data = torch.from_numpy(data).float()\n",
    "        self.target = torch.from_numpy(target).long()\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.target[index]\n",
    "\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset = T1Dataset(new_imgs, new_labels)\n",
    "train_size = int(0.6 * len(full_dataset))\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {'train': train_dataset, 'val': val_dataset, 'test': test_dataset}\n",
    "dataloaders_dict = {x: torch.utils.data.DataLoader(image_datasets[x], \n",
    "                                                   batch_size=batch_size,\n",
    "                                                   pin_memory=True,\n",
    "                                                   shuffle=True, num_workers=0) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    if is_inception and phase == 'train':\n",
    "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
    "                        outputs, aux_outputs = model(inputs)\n",
    "                        loss1 = criterion(outputs, labels)\n",
    "                        loss2 = criterion(aux_outputs, labels)\n",
    "                        loss = loss1 + 0.4*loss2\n",
    "                    else:\n",
    "                        outputs = model(inputs)\n",
    "                        loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\xieji/.torch\\models\\densenet121-a639ec97.pth\n",
      "32342954it [00:00, 60269938.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet(\n",
      "  (features): Sequential(\n",
      "    (conv0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (norm0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu0): ReLU(inplace)\n",
      "    (pool0): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (denseblock1): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition(\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock2): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(224, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(224, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition(\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock3): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(288, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(320, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(352, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(352, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(416, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(416, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(480, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer17): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer18): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer19): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer20): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer21): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer22): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer23): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer24): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition3): _Transition(\n",
      "      (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace)\n",
      "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
      "    )\n",
      "    (denseblock4): _DenseBlock(\n",
      "      (denselayer1): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(544, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(576, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(608, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(608, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(640, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(672, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer7): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(704, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(704, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer8): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(736, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(736, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer9): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer10): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(800, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(800, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer11): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(832, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer12): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(864, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(864, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer13): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(896, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(896, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer14): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(928, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(928, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer15): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(960, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer16): _DenseLayer(\n",
      "        (norm1): BatchNorm2d(992, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu1): ReLU(inplace)\n",
      "        (conv1): Conv2d(992, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu2): ReLU(inplace)\n",
      "        (conv2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (norm5): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=1024, out_features=2, bias=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ")\n"
     ]
    }
   ],
   "source": [
    "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if model_name == \"resnet\":\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"alexnet\":\n",
    "        \"\"\" Alexnet\n",
    "        \"\"\"\n",
    "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"vgg\":\n",
    "        \"\"\" VGG11_bn\n",
    "        \"\"\"\n",
    "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier[6].in_features\n",
    "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 256\n",
    "\n",
    "    elif model_name == \"inception\":\n",
    "        \"\"\" Inception v3\n",
    "        Be careful, expects (299,299) sized images and has auxiliary output\n",
    "        \"\"\"\n",
    "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        # Handle the auxilary net\n",
    "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
    "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        # Handle the primary net\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
    "        input_size = 299\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t classifier.weight\n",
      "\t classifier.bias\n"
     ]
    }
   ],
   "source": [
    "# Send the model to GPU\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "# Gather the parameters to be optimized/updated in this run. If we are\n",
    "#  finetuning we will be updating all parameters. However, if we are\n",
    "#  doing feature extract method, we will only update the parameters\n",
    "#  that we have just initialized, i.e. the parameters with requires_grad\n",
    "#  is True.\n",
    "params_to_update = model_ft.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model_ft.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6419 Acc: 0.6244\n",
      "val Loss: 0.5805 Acc: 0.7188\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.5566 Acc: 0.7177\n",
      "val Loss: 0.5717 Acc: 0.6756\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.5295 Acc: 0.7508\n",
      "val Loss: 0.5390 Acc: 0.7211\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.5155 Acc: 0.7543\n",
      "val Loss: 0.5284 Acc: 0.7701\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.4803 Acc: 0.7862\n",
      "val Loss: 0.5042 Acc: 0.7713\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.4737 Acc: 0.7842\n",
      "val Loss: 0.5894 Acc: 0.6791\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.4669 Acc: 0.7912\n",
      "val Loss: 0.4840 Acc: 0.7806\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.4407 Acc: 0.8060\n",
      "val Loss: 0.4793 Acc: 0.7713\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.4375 Acc: 0.8118\n",
      "val Loss: 0.4690 Acc: 0.7958\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.4236 Acc: 0.8149\n",
      "val Loss: 0.4656 Acc: 0.7760\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.4143 Acc: 0.8289\n",
      "val Loss: 0.4574 Acc: 0.7865\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.4033 Acc: 0.8344\n",
      "val Loss: 0.4599 Acc: 0.7830\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.4038 Acc: 0.8285\n",
      "val Loss: 0.4559 Acc: 0.8110\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.4047 Acc: 0.8285\n",
      "val Loss: 0.4506 Acc: 0.8086\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.4138 Acc: 0.8239\n",
      "val Loss: 0.4573 Acc: 0.8098\n",
      "\n",
      "Training complete in 2m 18s\n",
      "Best val Acc: 0.810968\n"
     ]
    }
   ],
   "source": [
    "# Setup the loss fxn\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train and evaluate\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/14\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 0.6120\n",
      "val Loss: 0.6239 Acc: 0.6826\n",
      "\n",
      "Epoch 1/14\n",
      "----------\n",
      "train Loss: 0.6042 Acc: 0.6956\n",
      "val Loss: 0.5833 Acc: 0.7106\n",
      "\n",
      "Epoch 2/14\n",
      "----------\n",
      "train Loss: 0.5556 Acc: 0.7321\n",
      "val Loss: 0.5306 Acc: 0.7468\n",
      "\n",
      "Epoch 3/14\n",
      "----------\n",
      "train Loss: 0.5027 Acc: 0.7636\n",
      "val Loss: 0.7873 Acc: 0.5741\n",
      "\n",
      "Epoch 4/14\n",
      "----------\n",
      "train Loss: 0.4446 Acc: 0.8033\n",
      "val Loss: 0.4372 Acc: 0.8121\n",
      "\n",
      "Epoch 5/14\n",
      "----------\n",
      "train Loss: 0.3327 Acc: 0.8779\n",
      "val Loss: 0.3472 Acc: 0.8576\n",
      "\n",
      "Epoch 6/14\n",
      "----------\n",
      "train Loss: 0.2795 Acc: 0.9024\n",
      "val Loss: 0.4456 Acc: 0.7760\n",
      "\n",
      "Epoch 7/14\n",
      "----------\n",
      "train Loss: 0.1825 Acc: 0.9456\n",
      "val Loss: 0.3139 Acc: 0.8471\n",
      "\n",
      "Epoch 8/14\n",
      "----------\n",
      "train Loss: 0.1059 Acc: 0.9728\n",
      "val Loss: 0.2550 Acc: 0.8996\n",
      "\n",
      "Epoch 9/14\n",
      "----------\n",
      "train Loss: 0.1453 Acc: 0.9452\n",
      "val Loss: 3.9238 Acc: 0.4481\n",
      "\n",
      "Epoch 10/14\n",
      "----------\n",
      "train Loss: 0.1090 Acc: 0.9650\n",
      "val Loss: 1.0207 Acc: 0.6278\n",
      "\n",
      "Epoch 11/14\n",
      "----------\n",
      "train Loss: 0.0962 Acc: 0.9689\n",
      "val Loss: 0.5073 Acc: 0.8016\n",
      "\n",
      "Epoch 12/14\n",
      "----------\n",
      "train Loss: 0.0567 Acc: 0.9821\n",
      "val Loss: 1.6290 Acc: 0.5554\n",
      "\n",
      "Epoch 13/14\n",
      "----------\n",
      "train Loss: 0.0351 Acc: 0.9903\n",
      "val Loss: 0.3111 Acc: 0.8763\n",
      "\n",
      "Epoch 14/14\n",
      "----------\n",
      "train Loss: 0.0737 Acc: 0.9728\n",
      "val Loss: 0.3747 Acc: 0.8751\n",
      "\n",
      "Training complete in 5m 30s\n",
      "Best val Acc: 0.899650\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the non-pretrained version of the model used for this run\n",
    "scratch_model,_ = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=False)\n",
    "scratch_model = scratch_model.to(device)\n",
    "scratch_optimizer = optim.SGD(scratch_model.parameters(), lr=0.001, momentum=0.9)\n",
    "scratch_criterion = nn.CrossEntropyLoss()\n",
    "_,scratch_hist = train_model(scratch_model, dataloaders_dict, scratch_criterion, scratch_optimizer, num_epochs=num_epochs, is_inception=(model_name==\"inception\"))\n",
    "\n",
    "# Plot the training curves of validation accuracy vs. number\n",
    "#  of training epochs for the transfer learning method and\n",
    "#  the model trained from scratch\n",
    "ohist = []\n",
    "shist = []\n",
    "\n",
    "ohist = [h.cpu().numpy() for h in hist]\n",
    "shist = [h.cpu().numpy() for h in scratch_hist]\n",
    "\n",
    "plt.title(\"Validation Accuracy vs. Number of Training Epochs\")\n",
    "plt.xlabel(\"Training Epochs\")\n",
    "plt.ylabel(\"Validation Accuracy\")\n",
    "plt.plot(range(1,num_epochs+1),ohist,label=\"Pretrained\")\n",
    "plt.plot(range(1,num_epochs+1),shist,label=\"Scratch\")\n",
    "plt.ylim((0,1.))\n",
    "plt.xticks(np.arange(1, num_epochs+1, 1.0))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
